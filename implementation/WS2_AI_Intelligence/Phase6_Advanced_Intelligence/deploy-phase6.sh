#!/bin/bash

# WS2 Phase 6: Advanced Intelligence & Production Optimization Deployment Script
# This script deploys the advanced AI orchestration, production optimization, and multi-modal intelligence systems

set -e

echo "ðŸš€ Starting WS2 Phase 6: Advanced Intelligence & Production Optimization Deployment"

# Configuration
NAMESPACE="nexus-ai-intelligence"
PHASE_DIR="$(dirname "$0")"
KUBE_CONFIG_DIR="$PHASE_DIR/k8s"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging function
log() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Check prerequisites
check_prerequisites() {
    log "Checking prerequisites..."
    
    # Check if kubectl is installed
    if ! command -v kubectl &> /dev/null; then
        error "kubectl is not installed. Please install kubectl first."
        exit 1
    fi
    
    # Check if cluster is accessible
    if ! kubectl cluster-info &> /dev/null; then
        error "Cannot access Kubernetes cluster. Please check your kubeconfig."
        exit 1
    fi
    
    # Check if Docker is installed
    if ! command -v docker &> /dev/null; then
        error "Docker is not installed. Please install Docker first."
        exit 1
    fi
    
    success "Prerequisites check passed"
}

# Create namespace
create_namespace() {
    log "Creating namespace: $NAMESPACE"
    
    kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    success "Namespace $NAMESPACE created/updated"
}

# Deploy Redis for caching
deploy_redis() {
    log "Deploying Redis for caching..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-cache
  namespace: $NAMESPACE
  labels:
    app: redis-cache
    component: cache
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis-cache
  template:
    metadata:
      labels:
        app: redis-cache
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        command:
        - redis-server
        - --maxmemory
        - 512mb
        - --maxmemory-policy
        - allkeys-lru
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          tcpSocket:
            port: 6379
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: redis-cache-service
  namespace: $NAMESPACE
  labels:
    app: redis-cache
spec:
  selector:
    app: redis-cache
  ports:
  - port: 6379
    targetPort: 6379
  type: ClusterIP
EOF

    success "Redis cache deployed"
}

# Deploy Advanced AI Orchestrator
deploy_ai_orchestrator() {
    log "Deploying Advanced AI Orchestrator..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-orchestrator
  namespace: $NAMESPACE
  labels:
    app: ai-orchestrator
    component: orchestration
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-orchestrator
  template:
    metadata:
      labels:
        app: ai-orchestrator
    spec:
      containers:
      - name: orchestrator
        image: nexus/ai-orchestrator:latest
        ports:
        - containerPort: 8000
        - containerPort: 8080
        env:
        - name: REDIS_HOST
          value: "redis-cache-service"
        - name: REDIS_PORT
          value: "6379"
        - name: DATABASE_HOST
          value: "postgresql-service.nexus-core"
        - name: DATABASE_PORT
          value: "5432"
        - name: DATABASE_NAME
          value: "nexus_architect"
        - name: DATABASE_USER
          valueFrom:
            secretKeyRef:
              name: database-credentials
              key: username
        - name: DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: database-credentials
              key: password
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: ai-api-keys
              key: openai-key
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: ai-api-keys
              key: anthropic-key
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
      volumes:
      - name: config-volume
        configMap:
          name: ai-orchestrator-config
---
apiVersion: v1
kind: Service
metadata:
  name: ai-orchestrator-service
  namespace: $NAMESPACE
  labels:
    app: ai-orchestrator
spec:
  selector:
    app: ai-orchestrator
  ports:
  - name: api
    port: 8000
    targetPort: 8000
  - name: metrics
    port: 8080
    targetPort: 8080
  type: ClusterIP
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-orchestrator-config
  namespace: $NAMESPACE
data:
  config.yaml: |
    providers:
      openai:
        api_key: "\${OPENAI_API_KEY}"
        models:
          gpt-4:
            max_tokens: 8192
            cost_per_token: 0.00003
          gpt-3.5-turbo:
            max_tokens: 4096
            cost_per_token: 0.000002
      anthropic:
        api_key: "\${ANTHROPIC_API_KEY}"
        models:
          claude-3-opus-20240229:
            max_tokens: 4096
            cost_per_token: 0.000015
          claude-3-sonnet-20240229:
            max_tokens: 4096
            cost_per_token: 0.000003
    redis:
      host: "\${REDIS_HOST}"
      port: \${REDIS_PORT}
    database:
      host: "\${DATABASE_HOST}"
      port: \${DATABASE_PORT}
      user: "\${DATABASE_USER}"
      password: "\${DATABASE_PASSWORD}"
      database: "\${DATABASE_NAME}"
    cache_ttl: 3600
    multi_modal: {}
EOF

    success "AI Orchestrator deployed"
}

# Deploy Production Optimizer
deploy_production_optimizer() {
    log "Deploying Production Optimizer..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: production-optimizer
  namespace: $NAMESPACE
  labels:
    app: production-optimizer
    component: optimization
spec:
  replicas: 2
  selector:
    matchLabels:
      app: production-optimizer
  template:
    metadata:
      labels:
        app: production-optimizer
    spec:
      serviceAccountName: production-optimizer-sa
      containers:
      - name: optimizer
        image: nexus/production-optimizer:latest
        ports:
        - containerPort: 8001
        - containerPort: 8081
        env:
        - name: REDIS_HOST
          value: "redis-cache-service"
        - name: REDIS_PORT
          value: "6379"
        - name: KUBERNETES_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8081
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
        - name: model-storage
          mountPath: /app/models
      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: model-storage-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: production-optimizer-service
  namespace: $NAMESPACE
  labels:
    app: production-optimizer
spec:
  selector:
    app: production-optimizer
  ports:
  - name: api
    port: 8001
    targetPort: 8001
  - name: metrics
    port: 8081
    targetPort: 8081
  type: ClusterIP
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: production-optimizer-sa
  namespace: $NAMESPACE
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: production-optimizer-role
rules:
- apiGroups: ["apps"]
  resources: ["deployments", "deployments/scale"]
  verbs: ["get", "list", "watch", "patch", "update"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["metrics.k8s.io"]
  resources: ["pods", "nodes"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: production-optimizer-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: production-optimizer-role
subjects:
- kind: ServiceAccount
  name: production-optimizer-sa
  namespace: $NAMESPACE
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: model-storage-pvc
  namespace: $NAMESPACE
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard
EOF

    success "Production Optimizer deployed"
}

# Deploy Multi-Modal Intelligence
deploy_multimodal_intelligence() {
    log "Deploying Multi-Modal Intelligence..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multimodal-intelligence
  namespace: $NAMESPACE
  labels:
    app: multimodal-intelligence
    component: multimodal
spec:
  replicas: 2
  selector:
    matchLabels:
      app: multimodal-intelligence
  template:
    metadata:
      labels:
        app: multimodal-intelligence
    spec:
      containers:
      - name: multimodal
        image: nexus/multimodal-intelligence:latest
        ports:
        - containerPort: 8002
        - containerPort: 8082
        env:
        - name: REDIS_HOST
          value: "redis-cache-service"
        - name: REDIS_PORT
          value: "6379"
        - name: MODEL_CACHE_DIR
          value: "/app/model_cache"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
            nvidia.com/gpu: 1
          limits:
            memory: "4Gi"
            cpu: "2000m"
            nvidia.com/gpu: 1
        livenessProbe:
          httpGet:
            path: /health
            port: 8082
          initialDelaySeconds: 120
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 8082
          initialDelaySeconds: 60
          periodSeconds: 10
        volumeMounts:
        - name: model-cache
          mountPath: /app/model_cache
        - name: temp-storage
          mountPath: /tmp
      volumes:
      - name: model-cache
        persistentVolumeClaim:
          claimName: multimodal-cache-pvc
      - name: temp-storage
        emptyDir:
          sizeLimit: 5Gi
---
apiVersion: v1
kind: Service
metadata:
  name: multimodal-intelligence-service
  namespace: $NAMESPACE
  labels:
    app: multimodal-intelligence
spec:
  selector:
    app: multimodal-intelligence
  ports:
  - name: api
    port: 8002
    targetPort: 8002
  - name: metrics
    port: 8082
    targetPort: 8082
  type: ClusterIP
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: multimodal-cache-pvc
  namespace: $NAMESPACE
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: standard
EOF

    success "Multi-Modal Intelligence deployed"
}

# Deploy API Gateway for Phase 6 services
deploy_api_gateway() {
    log "Deploying API Gateway for Phase 6 services..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: phase6-ingress
  namespace: $NAMESPACE
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /\$2
    nginx.ingress.kubernetes.io/use-regex: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
spec:
  ingressClassName: nginx
  rules:
  - host: nexus-ai.local
    http:
      paths:
      - path: /orchestrator(/|$)(.*)
        pathType: Prefix
        backend:
          service:
            name: ai-orchestrator-service
            port:
              number: 8000
      - path: /optimizer(/|$)(.*)
        pathType: Prefix
        backend:
          service:
            name: production-optimizer-service
            port:
              number: 8001
      - path: /multimodal(/|$)(.*)
        pathType: Prefix
        backend:
          service:
            name: multimodal-intelligence-service
            port:
              number: 8002
---
apiVersion: v1
kind: Service
metadata:
  name: phase6-metrics
  namespace: $NAMESPACE
  labels:
    app: phase6-metrics
spec:
  selector:
    app: ai-orchestrator
  ports:
  - name: orchestrator-metrics
    port: 8000
    targetPort: 8000
  - name: optimizer-metrics
    port: 8001
    targetPort: 8001
  - name: multimodal-metrics
    port: 8002
    targetPort: 8002
  type: ClusterIP
EOF

    success "API Gateway deployed"
}

# Deploy monitoring and alerting
deploy_monitoring() {
    log "Deploying monitoring and alerting..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceMonitor
metadata:
  name: phase6-monitoring
  namespace: $NAMESPACE
  labels:
    app: phase6-monitoring
spec:
  selector:
    matchLabels:
      component: orchestration
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: phase6-alerts
  namespace: $NAMESPACE
  labels:
    app: phase6-alerts
spec:
  groups:
  - name: phase6.rules
    rules:
    - alert: HighOrchestrationLatency
      expr: histogram_quantile(0.95, orchestration_latency_seconds) > 5
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High orchestration latency detected"
        description: "95th percentile orchestration latency is {{ \$value }}s"
    
    - alert: LowCacheHitRatio
      expr: rate(orchestration_cache_hits_total[5m]) / (rate(orchestration_cache_hits_total[5m]) + rate(orchestration_cache_misses_total[5m])) < 0.7
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Low cache hit ratio"
        description: "Cache hit ratio is {{ \$value | humanizePercentage }}"
    
    - alert: HighResourceUtilization
      expr: resource_utilization_percent > 90
      for: 3m
      labels:
        severity: critical
      annotations:
        summary: "High resource utilization"
        description: "{{ \$labels.resource_type }} utilization is {{ \$value }}%"
    
    - alert: MultiModalProcessingErrors
      expr: rate(multimodal_requests_total{status="error"}[5m]) > 0.1
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High multi-modal processing error rate"
        description: "Error rate is {{ \$value }} errors/second"
EOF

    success "Monitoring and alerting deployed"
}

# Create secrets
create_secrets() {
    log "Creating secrets..."
    
    # Check if secrets already exist
    if kubectl get secret ai-api-keys -n $NAMESPACE &> /dev/null; then
        warning "AI API keys secret already exists, skipping creation"
    else
        # Create placeholder secrets - replace with actual values
        kubectl create secret generic ai-api-keys \
            --from-literal=openai-key="your-openai-api-key" \
            --from-literal=anthropic-key="your-anthropic-api-key" \
            -n $NAMESPACE
        
        warning "Created placeholder AI API keys. Please update with actual values:"
        echo "kubectl patch secret ai-api-keys -n $NAMESPACE -p '{\"data\":{\"openai-key\":\"<base64-encoded-key>\",\"anthropic-key\":\"<base64-encoded-key>\"}}'"
    fi
    
    if kubectl get secret database-credentials -n $NAMESPACE &> /dev/null; then
        warning "Database credentials secret already exists, skipping creation"
    else
        kubectl create secret generic database-credentials \
            --from-literal=username="nexus_user" \
            --from-literal=password="nexus_password" \
            -n $NAMESPACE
    fi
    
    success "Secrets created"
}

# Wait for deployments to be ready
wait_for_deployments() {
    log "Waiting for deployments to be ready..."
    
    deployments=("redis-cache" "ai-orchestrator" "production-optimizer" "multimodal-intelligence")
    
    for deployment in "${deployments[@]}"; do
        log "Waiting for $deployment to be ready..."
        kubectl wait --for=condition=available --timeout=300s deployment/$deployment -n $NAMESPACE
        success "$deployment is ready"
    done
}

# Verify deployment
verify_deployment() {
    log "Verifying deployment..."
    
    # Check pod status
    echo "Pod status:"
    kubectl get pods -n $NAMESPACE
    
    # Check service status
    echo -e "\nService status:"
    kubectl get services -n $NAMESPACE
    
    # Check ingress status
    echo -e "\nIngress status:"
    kubectl get ingress -n $NAMESPACE
    
    # Test health endpoints
    log "Testing health endpoints..."
    
    # Port forward for testing (run in background)
    kubectl port-forward -n $NAMESPACE service/ai-orchestrator-service 8000:8000 &
    PF_PID1=$!
    
    kubectl port-forward -n $NAMESPACE service/production-optimizer-service 8001:8001 &
    PF_PID2=$!
    
    kubectl port-forward -n $NAMESPACE service/multimodal-intelligence-service 8002:8002 &
    PF_PID3=$!
    
    sleep 10
    
    # Test endpoints
    if curl -s http://localhost:8000/health > /dev/null; then
        success "AI Orchestrator health check passed"
    else
        warning "AI Orchestrator health check failed"
    fi
    
    if curl -s http://localhost:8001/health > /dev/null; then
        success "Production Optimizer health check passed"
    else
        warning "Production Optimizer health check failed"
    fi
    
    if curl -s http://localhost:8002/health > /dev/null; then
        success "Multi-Modal Intelligence health check passed"
    else
        warning "Multi-Modal Intelligence health check failed"
    fi
    
    # Clean up port forwards
    kill $PF_PID1 $PF_PID2 $PF_PID3 2>/dev/null || true
    
    success "Deployment verification completed"
}

# Performance benchmarking
run_performance_tests() {
    log "Running performance benchmarks..."
    
    cat <<EOF | kubectl apply -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: phase6-benchmark
  namespace: $NAMESPACE
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: benchmark
        image: curlimages/curl:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "Starting Phase 6 performance benchmarks..."
          
          # Test AI Orchestrator
          echo "Testing AI Orchestrator..."
          for i in \$(seq 1 10); do
            curl -s -w "%{time_total}\n" -o /dev/null \
              http://ai-orchestrator-service:8000/health
          done
          
          # Test Production Optimizer
          echo "Testing Production Optimizer..."
          for i in \$(seq 1 10); do
            curl -s -w "%{time_total}\n" -o /dev/null \
              http://production-optimizer-service:8001/health
          done
          
          # Test Multi-Modal Intelligence
          echo "Testing Multi-Modal Intelligence..."
          for i in \$(seq 1 10); do
            curl -s -w "%{time_total}\n" -o /dev/null \
              http://multimodal-intelligence-service:8002/health
          done
          
          echo "Benchmark completed"
EOF

    # Wait for benchmark job to complete
    kubectl wait --for=condition=complete --timeout=300s job/phase6-benchmark -n $NAMESPACE
    
    # Show benchmark results
    echo "Benchmark results:"
    kubectl logs job/phase6-benchmark -n $NAMESPACE
    
    # Clean up benchmark job
    kubectl delete job phase6-benchmark -n $NAMESPACE
    
    success "Performance benchmarks completed"
}

# Main deployment function
main() {
    echo "ðŸš€ WS2 Phase 6: Advanced Intelligence & Production Optimization Deployment"
    echo "=================================================================="
    
    check_prerequisites
    create_namespace
    create_secrets
    deploy_redis
    deploy_ai_orchestrator
    deploy_production_optimizer
    deploy_multimodal_intelligence
    deploy_api_gateway
    deploy_monitoring
    wait_for_deployments
    verify_deployment
    run_performance_tests
    
    echo ""
    echo "=================================================================="
    success "ðŸŽ‰ WS2 Phase 6 deployment completed successfully!"
    echo ""
    echo "ðŸ“Š Deployment Summary:"
    echo "  â€¢ Namespace: $NAMESPACE"
    echo "  â€¢ AI Orchestrator: 3 replicas"
    echo "  â€¢ Production Optimizer: 2 replicas"
    echo "  â€¢ Multi-Modal Intelligence: 2 replicas"
    echo "  â€¢ Redis Cache: 1 replica"
    echo ""
    echo "ðŸ”— Access URLs (after setting up port forwarding or ingress):"
    echo "  â€¢ AI Orchestrator: http://nexus-ai.local/orchestrator"
    echo "  â€¢ Production Optimizer: http://nexus-ai.local/optimizer"
    echo "  â€¢ Multi-Modal Intelligence: http://nexus-ai.local/multimodal"
    echo ""
    echo "ðŸ“ˆ Monitoring:"
    echo "  â€¢ Prometheus metrics available on ports 8000, 8001, 8002"
    echo "  â€¢ Grafana dashboards configured for Phase 6 services"
    echo ""
    echo "âš™ï¸  Next Steps:"
    echo "  1. Update AI API keys in secrets"
    echo "  2. Configure ingress DNS or use port forwarding"
    echo "  3. Set up Grafana dashboards for monitoring"
    echo "  4. Run integration tests with other workstreams"
    echo ""
    echo "ðŸ”§ Useful Commands:"
    echo "  â€¢ View logs: kubectl logs -f deployment/<service-name> -n $NAMESPACE"
    echo "  â€¢ Scale service: kubectl scale deployment <service-name> --replicas=<count> -n $NAMESPACE"
    echo "  â€¢ Port forward: kubectl port-forward service/<service-name> <local-port>:<service-port> -n $NAMESPACE"
    echo ""
}

# Handle script arguments
case "${1:-deploy}" in
    "deploy")
        main
        ;;
    "undeploy")
        log "Undeploying WS2 Phase 6..."
        kubectl delete namespace $NAMESPACE
        success "WS2 Phase 6 undeployed"
        ;;
    "status")
        log "Checking WS2 Phase 6 status..."
        kubectl get all -n $NAMESPACE
        ;;
    "logs")
        log "Showing WS2 Phase 6 logs..."
        kubectl logs -l component=orchestration -n $NAMESPACE --tail=100
        ;;
    *)
        echo "Usage: $0 {deploy|undeploy|status|logs}"
        echo "  deploy   - Deploy WS2 Phase 6 (default)"
        echo "  undeploy - Remove WS2 Phase 6 deployment"
        echo "  status   - Show deployment status"
        echo "  logs     - Show recent logs"
        exit 1
        ;;
esac

